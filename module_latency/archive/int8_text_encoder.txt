<class 'torch.nn.modules.sparse.Embedding'> take 9.4633549451828e-05 secs for forwarding
<class 'torch.nn.modules.sparse.Embedding'> take 2.325698733329773e-05 secs for forwarding
<class 'transformers.models.clip.modeling_clip.CLIPTextEmbeddings'> take 0.0002394840121269226 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 0.0001268293708562851 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 6.432086229324341e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.0800700187683105e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.7514994144439697e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 9.644962847232819e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.767548620700836e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.67933714389801e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0007271803915500641 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.843226194381714e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 4.022754728794098e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.883056342601776e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001168418675661087 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0011600516736507416 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.801130414009094e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.6036595702171326e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9752030968666077e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8425827622413635e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.57886266708374e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.194785237312317e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022754728794098e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005752760916948318 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.808208465576172e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.4499913454055786e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.8273632526397705e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010741502046585083 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009367708116769791 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.619522511959076e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.5900622606277466e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.7377158403396606e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.849288284778595e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.523355841636658e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.153061985969543e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.980658948421478e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005657803267240524 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570721209049225e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.596767783164978e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.7925317883491516e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010839104652404785 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.000924479216337204 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.710419595241547e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.498978912830353e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8913840651512146e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.884678542613983e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.816349923610687e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.152689456939697e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.8761645555496216e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005696192383766174 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.808022201061249e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.463961184024811e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.7364661693573e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010685622692108154 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009420104324817657 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.423944771289825e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.596767783164978e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9752030968666077e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.6540830731391907e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.530061364173889e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.187893450260162e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022754728794098e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005705989897251129 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.675401866436005e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.4572556614875793e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.7785619497299194e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010692514479160309 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009258780628442764 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570721209049225e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.547780215740204e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.884306013584137e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.835690975189209e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.530061364173889e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.236881017684937e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.8761645555496216e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.000564035028219223 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.759220898151398e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.450363874435425e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.869272768497467e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010923109948635101 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009253881871700287 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.473118603229523e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.5060569643974304e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8353184461593628e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.7935951948165894e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.579048931598663e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.390362977981567e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.9810314774513245e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005662683397531509 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.843039929866791e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.359280526638031e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.7923455238342285e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010790489614009857 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009254571050405502 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570534944534302e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.5900622606277466e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9401853680610657e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.835504710674286e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.481446325778961e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.104074418544769e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.973953425884247e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005663391202688217 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570907473564148e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.450177609920502e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.785453736782074e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010692328214645386 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.000941593199968338 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.612630724906921e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.596954047679901e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.933107316493988e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.7796253561973572e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.473995745182037e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.145983934402466e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022754728794098e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.000565430149435997 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.759220898151398e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.499165177345276e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.8761645555496216e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001083221286535263 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009249001741409302 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.619708776473999e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.596767783164978e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.933293581008911e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.7863308787345886e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.432272493839264e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.0969963669776917e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.973953425884247e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005630552768707275 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.661432027816772e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.499165177345276e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.834255039691925e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010734423995018005 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009178463369607925 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570534944534302e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.5060569643974304e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8776004910469055e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8423964977264404e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.439164280891418e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.159767508506775e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.0300190448760986e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005662683397531509 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.668696343898773e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.4572556614875793e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.7785619497299194e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010692328214645386 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009220372885465622 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.654540240764618e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.5548582673072815e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.7867034077644348e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.7935951948165894e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.620772182941437e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.0619786381721497e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.8761645555496216e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005644522607326508 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.619522511959076e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.498978912830353e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.8271769881248474e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010832399129867554 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009253900498151779 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoder'> take 0.011718982830643654 secs for forwarding
<class 'torch.nn.modules.normalization.LayerNorm'> take 6.243772804737091e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPTextTransformer'> take 0.012466555461287498 secs for forwarding
<class 'quant.text_encoder.INT8CLIPTextModel'> take 0.012498265132308006 secs for forwarding
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
0.4341471195220947
<class 'torch.nn.modules.sparse.Embedding'> take 9.268149733543396e-05 secs for forwarding
<class 'torch.nn.modules.sparse.Embedding'> take 2.6537105441093445e-05 secs for forwarding
<class 'transformers.models.clip.modeling_clip.CLIPTextEmbeddings'> take 0.00024311617016792297 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 0.00012864544987678528 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 6.816349923610687e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.170780837535858e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9889866709709167e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 9.512342512607574e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.72563910484314e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.916824400424957e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0007366091012954712 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.996708154678345e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 4.0646642446517944e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.9672479033470154e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011733360588550568 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0011733230203390121 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.668323814868927e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.547966480255127e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8423964977264404e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.88449227809906e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 7.850304245948792e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.201863288879395e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.925152122974396e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0006027240306138992 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.703527808189392e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.498978912830353e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.925152122974396e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011034682393074036 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009680595248937607 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.619708776473999e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.596767783164978e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9334798455238342e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8423964977264404e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.578676402568817e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.627663969993591e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022940993309021e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005771629512310028 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.703341543674469e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 5.3007155656814575e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022754728794098e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00013053230941295624 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009584948420524597 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570721209049225e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.5546720027923584e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.7375295758247375e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.751871943473816e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.579235196113586e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.194785237312317e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022940993309021e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005715042352676392 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.577799260616302e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.5898759961128235e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.736652433872223e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010930001735687256 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009320247918367386 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.521733641624451e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.547780215740204e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.933293581008911e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.88449227809906e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.481260061264038e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.103888154029846e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.392862319946289e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005725547671318054 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.66851007938385e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.4499913454055786e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.7297606468200684e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010741502046585083 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009343959391117096 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.480010390281677e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.498978912830353e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.12216579914093e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.317743539810181e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.627850234508514e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.243772804737091e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022754728794098e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005833785980939865 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.710419595241547e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.6034733057022095e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.778189420700073e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011013820767402649 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009480863809585571 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.661618292331696e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.6384910345077515e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9822811484336853e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9824674129486084e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.578676402568817e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.202049553394318e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.0158629417419434e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005719941109418869 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.382221519947052e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.408268094062805e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.883242607116699e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010888464748859406 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009382385760545731 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 0.00010301731526851654 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.6388635635375977e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.98917293548584e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.919510006904602e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.425194442272186e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.250664591789246e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.967061638832092e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005747880786657333 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.626600563526154e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.450177609920502e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.876350820064545e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001074131578207016 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009589847177267075 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.563643157482147e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.408454358577728e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.6540830731391907e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8423964977264404e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.481260061264038e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.15287572145462e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.9247795939445496e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005645211786031723 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.710419595241547e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.687664866447449e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.785453736782074e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011251121759414673 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009283199906349182 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570534944534302e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.499351441860199e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9401853680610657e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.695806324481964e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.488151848316193e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.159953773021698e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022754728794098e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005643852055072784 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.56382942199707e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.4499913454055786e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.834255039691925e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010790303349494934 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009221062064170837 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.905997335910797e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.645755350589752e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8427690267562866e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.835504710674286e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.439164280891418e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.187893450260162e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.071556031703949e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005677342414855957 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.710419595241547e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.4499913454055786e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.890134394168854e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011216476559638977 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.000940544530749321 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.709169924259186e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.457069396972656e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.835690975189209e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9752030968666077e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.529875099658966e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.159767508506775e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.071742296218872e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005861744284629822 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.703155279159546e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.596767783164978e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.883242607116699e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010887905955314636 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009561888873577118 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoder'> take 0.011804679408669472 secs for forwarding
<class 'torch.nn.modules.normalization.LayerNorm'> take 3.498978912830353e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPTextTransformer'> take 0.012538423761725426 secs for forwarding
<class 'quant.text_encoder.INT8CLIPTextModel'> take 0.012569153681397438 secs for forwarding
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
0.43514323234558105
<class 'torch.nn.modules.sparse.Embedding'> take 9.6101313829422e-05 secs for forwarding
<class 'torch.nn.modules.sparse.Embedding'> take 2.3186206817626953e-05 secs for forwarding
<class 'transformers.models.clip.modeling_clip.CLIPTextEmbeddings'> take 0.00024458393454551697 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 0.00013570114970207214 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 6.907247006893158e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.219582140445709e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.505870699882507e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 0.00010308250784873962 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.760656833648682e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 5.21000474691391e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0008095204830169678 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.234195411205292e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 4.0158629417419434e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.253163933753967e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00012005865573883057 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0012556631118059158 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.087418973445892e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.5410746932029724e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9403716325759888e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8776004910469055e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.669573485851288e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.243772804737091e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022754728794098e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005729738622903824 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.808022201061249e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.547966480255127e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.9249658584594727e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010923296213150024 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009429175406694412 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.710419595241547e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.9249658584594727e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9822811484336853e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.6959925889968872e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.530247628688812e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 7.333420217037201e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.1136518120765686e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0006377138197422028 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.89891928434372e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.450177609920502e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.7433579564094543e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001083221286535263 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009996984153985977 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.619522511959076e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.7433579564094543e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.835690975189209e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.884306013584137e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.579048931598663e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.145983934402466e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.9249658584594727e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005724839866161346 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.661432027816772e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 4.0648505091667175e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.7785619497299194e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011921487748622894 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009519308805465698 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.619522511959076e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 4.16245311498642e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.849288284778595e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.212690353393555e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.858259439468384e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.292760372161865e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.211440682411194e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005891062319278717 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.619522511959076e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.457069396972656e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.882870078086853e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010971911251544952 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.000953255221247673 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570534944534302e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.499165177345276e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.88449227809906e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8423964977264404e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.397254765033722e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.250664591789246e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.93204391002655e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005625654011964798 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570534944534302e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.596767783164978e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.596954047679901e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010552816092967987 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009169392287731171 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.564015686511993e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.5550445318222046e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9334798455238342e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.933293581008911e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.481260061264038e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 7.333233952522278e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.925338387489319e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005791205912828445 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.654353976249695e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.4499913454055786e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.392676055431366e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00012208148837089539 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.000961916521191597 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.75214284658432e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.834068775177002e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.212690353393555e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.0308961868286133e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.718933582305908e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.530061364173889e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.260428249835968e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0006145276129245758 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.080713450908661e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.869272768497467e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.260241985321045e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001187305897474289 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.001005847007036209 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.940828800201416e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.834255039691925e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.841333091259003e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.547780215740204e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.858445703983307e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.522983312606812e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.308857023715973e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0006349198520183563 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.087418973445892e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.7921592593193054e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.260055720806122e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011970661580562592 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0010260995477437973 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.185207843780518e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.834441304206848e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.121979534626007e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9752030968666077e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.809644401073456e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.530061364173889e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.071556031703949e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0006131324917078018 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.940828800201416e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.7364661693573e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.120729863643646e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011453963816165924 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009963493794202805 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.89891928434372e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.834255039691925e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.212690353393555e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.073178231716156e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 7.717497646808624e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.522983312606812e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.3509528040885925e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0006519630551338196 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.045695722103119e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.7785619497299194e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.260241985321045e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00012005679309368134 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0010441206395626068 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.905811071395874e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.8759782910346985e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.156810998916626e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.073364496231079e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.711483001708984e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.579048931598663e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.3021515011787415e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0006140414625406265 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.094310760498047e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.9249658584594727e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.392676055431366e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00012159161269664764 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0010048672556877136 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoder'> take 0.012302432209253311 secs for forwarding
<class 'torch.nn.modules.normalization.LayerNorm'> take 3.596767783164978e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPTextTransformer'> take 0.01301068626344204 secs for forwarding
<class 'quant.text_encoder.INT8CLIPTextModel'> take 0.013042323291301727 secs for forwarding
0.5483524799346924
<class 'torch.nn.modules.sparse.Embedding'> take 0.00011635199189186096 secs for forwarding
<class 'torch.nn.modules.sparse.Embedding'> take 2.647005021572113e-05 secs for forwarding
<class 'transformers.models.clip.modeling_clip.CLIPTextEmbeddings'> take 0.00032070837914943695 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 0.00013248808681964874 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 7.040053606033325e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.219582140445709e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9752030968666077e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 0.00010594725608825684 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.858445703983307e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 5.5383890867233276e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0007834713906049728 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.09449702501297e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 4.1136518120765686e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.1136518120765686e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00012396648526191711 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0012434441596269608 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.703155279159546e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.687664866447449e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.0800700187683105e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.989359200000763e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.718747317790985e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.439350545406342e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.309229552745819e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005918275564908981 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.857196033000946e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.687664866447449e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.1136518120765686e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011684373021125793 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009693894535303116 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.808022201061249e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.645569086074829e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9752030968666077e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9401853680610657e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.62095844745636e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.292760372161865e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.260428249835968e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.000581003725528717 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 9.456463158130646e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 4.0648505091667175e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.966875374317169e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011963583528995514 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009845439344644547 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 0.0001083221286535263 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.736279904842377e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.1149014830589294e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.0308961868286133e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.669573485851288e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.390362977981567e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.260241985321045e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005899444222450256 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.8568235039711e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.6949291825294495e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.97413969039917e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011258386075496674 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.000996345654129982 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.801316678524017e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.596767783164978e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.884306013584137e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9403716325759888e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.481073796749115e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.285496056079865e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.16245311498642e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005747880786657333 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.905997335910797e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.5898759961128235e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.883056342601776e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011314265429973602 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009504593908786774 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.612630724906921e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.687664866447449e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.0312687158584595e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8423964977264404e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.579235196113586e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.243586540222168e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.211440682411194e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005823317915201187 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.806958794593811e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 4.358217120170593e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.344061017036438e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00012732110917568207 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009802840650081635 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.710419595241547e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.785453736782074e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.0240043997764587e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9822811484336853e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.57886266708374e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.341561675071716e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.393048584461212e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005875714123249054 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.842853665351868e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.505870699882507e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.918260335922241e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001130029559135437 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009732283651828766 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 0.00012298859655857086 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 5.056522786617279e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.359466791152954e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.037974238395691e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 7.04694539308548e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.669573485851288e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.3509528040885925e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.000655733048915863 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.373893797397614e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.966875374317169e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.358217120170593e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001234784722328186 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0011023655533790588 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.331984281539917e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.980658948421478e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.310292959213257e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.121979534626007e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.907433271408081e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.62095844745636e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 5.161203444004059e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0006453283131122589 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.65347683429718e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.93204391002655e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.260241985321045e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011963769793510437 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0010512452572584152 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.325092494487762e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.973953425884247e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.2125040888786316e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.1638890504837036e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 7.00484961271286e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.488151848316193e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.3023377656936646e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0006297528743743896 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.136406540870667e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.917887806892395e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.260241985321045e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001234784722328186 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.00103042833507061 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.09449702501297e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.97413969039917e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.359466791152954e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.0798837542533875e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.956234574317932e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.760656833648682e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.399940371513367e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0006312206387519836 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 0.00010552816092967987 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.883242607116699e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 5.356781184673309e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00013856403529644012 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0010688398033380508 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.275918662548065e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 4.0648505091667175e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.359466791152954e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.261491656303406e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.851367652416229e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.481073796749115e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.260241985321045e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0006268899887800217 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.283182978630066e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.9322301745414734e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.3023377656936646e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001229904592037201 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0010261684656143188 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoder'> take 0.012672308832406998 secs for forwarding
<class 'torch.nn.modules.normalization.LayerNorm'> take 3.973767161369324e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPTextTransformer'> take 0.013586454093456268 secs for forwarding
<class 'quant.text_encoder.INT8CLIPTextModel'> take 0.013662092387676239 secs for forwarding
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
0.4660189151763916
<class 'torch.nn.modules.sparse.Embedding'> take 9.316578507423401e-05 secs for forwarding
<class 'torch.nn.modules.sparse.Embedding'> take 2.172030508518219e-05 secs for forwarding
<class 'transformers.models.clip.modeling_clip.CLIPTextEmbeddings'> take 0.00023655034601688385 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 0.00012962333858013153 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 7.333233952522278e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.0798837542533875e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9822811484336853e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 0.00010266713798046112 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 7.144734263420105e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 7.570721209049225e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0007877331227064133 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.045695722103119e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 4.40012663602829e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.9249658584594727e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001206863671541214 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0012347828596830368 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.038245141506195e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.540888428688049e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9820948839187622e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.933293581008911e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 7.249601185321808e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.285496056079865e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.8761645555496216e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005866587162017822 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.801130414009094e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.5898759961128235e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.0646642446517944e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.000112093985080719 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009561870247125626 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.75214284658432e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.603845834732056e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8776004910469055e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8425827622413635e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.488151848316193e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.250850856304169e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.973767161369324e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005701817572116852 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.717497646808624e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.408454358577728e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.834255039691925e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010832399129867554 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009348858147859573 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570907473564148e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.492273390293121e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.884306013584137e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.121979534626007e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 7.661618292331696e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.201677024364471e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.015490412712097e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.000596093013882637 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.668323814868927e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.785081207752228e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.7435442209243774e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011125579476356506 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009589828550815582 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570907473564148e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.499351441860199e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.884306013584137e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.7935951948165894e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.571970880031586e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.243586540222168e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.0646642446517944e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005700401961803436 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 8.897669613361359e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.457069396972656e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.729574382305145e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001083221286535263 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009452942758798599 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.892027497291565e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.5900622606277466e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.884306013584137e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9403716325759888e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.579048931598663e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.201490759849548e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022940993309021e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005714353173971176 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.612630724906921e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.7785619497299194e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.9247795939445496e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011356174945831299 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009429212659597397 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.612630724906921e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.596767783164978e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.88449227809906e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9336661100387573e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.481446325778961e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.201863288879395e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.309229552745819e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005719941109418869 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570721209049225e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.49879264831543e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.890320658683777e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011076778173446655 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009373314678668976 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.528811693191528e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.499165177345276e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.88449227809906e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.884306013584137e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.390362977981567e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.194785237312317e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.973767161369324e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005678031593561172 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.66851007938385e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.4572556614875793e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.8761645555496216e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010881200432777405 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009272750467061996 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.654353976249695e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.603845834732056e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.933293581008911e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.835690975189209e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.530061364173889e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.139092147350311e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022754728794098e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005710180848836899 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.654353976249695e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.8411468267440796e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.6874786019325256e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00011118687689304352 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009675044566392899 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.81528651714325e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.547780215740204e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9403716325759888e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8776004910469055e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.481260061264038e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.104074418544769e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.93204391002655e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005659181624650955 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.905811071395874e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.499165177345276e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.8271769881248474e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010888278484344482 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009325128048658371 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.570721209049225e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.408268094062805e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.884306013584137e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.7863308787345886e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.432272493839264e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.194785237312317e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.015490412712097e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.0005638916045427322 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.905811071395874e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.450177609920502e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.820471465587616e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.0001083221286535263 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009301379323005676 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.661618292331696e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 3.498978912830353e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.8772279620170593e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8Linear'> take 2.9401853680610657e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_F32T'> take 6.536953151226044e-05 secs for forwarding
<class 'torch_int.nn.bmm.BMM_S8T_S8N_S8T'> take 6.055273115634918e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 4.022754728794098e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPAttention'> take 0.000562567263841629 secs for forwarding
<class 'torch_int.nn.fused.LayerNormQ'> take 7.759220898151398e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8B8O8LinearReLU'> take 3.603845834732056e-05 secs for forwarding
<class 'torch_int.nn.linear.W8A8BFP32OFP32Linear'> take 3.876350820064545e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPMLP'> take 0.00010873936116695404 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoderLayer'> take 0.0009235013276338577 secs for forwarding
<class 'quant.text_encoder.INT8CLIPEncoder'> take 0.01183450035750866 secs for forwarding
<class 'torch.nn.modules.normalization.LayerNorm'> take 3.408268094062805e-05 secs for forwarding
<class 'quant.text_encoder.INT8CLIPTextTransformer'> take 0.01253276877105236 secs for forwarding
<class 'quant.text_encoder.INT8CLIPTextModel'> take 0.012562591582536697 secs for forwarding
0.43631672859191895